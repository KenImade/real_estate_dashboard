
services:
    webserver:
        build:
            context: .
            dockerfile: Dockerfile
        image: apache/airflow:2.9.0-python3.9
        entrypoint: ['/opt/airflow/scripts/entrypoint.sh']
        depends_on:
            - postgres
        environment:
            - LOAD_EX=n
            - EXECUTOR=CeleryExecutor
            - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
            - AIRFLOW_UID=1000
            - AIRFLOW__LOGGING__BASE_LOG_FOLDER=/opt/airflow/logs
            - AIRFLOW__LOGGING__LOGGING_LEVEL=INFO
            - GOOGLE_APPLICATION_CREDENTIALS=/opt/airflow/secrets/key.json
        logging:
            options:
                max-size: 10m
                max-file: "3"
        volumes:
            - ./dags:/opt/airflow/dags
            - ./scripts/entrypoint.sh:/opt/airflow/scripts/entrypoint.sh
            - ./logs:/opt/airflow/logs
            - ./data:/opt/airflow/data
            - ${GOOGLE_APPLICATION_CREDENTIALS_LOCAL}:/opt/airflow/secrets/key.json:ro
            - ./dbt_real_estate/profiles.yml:/usr/local/airflow/dbt/profiles.yml
        ports:
            - "8080:8080"
        healthcheck:
            test: ["CMD-SHELL", "curl --fail http://localhost:8080/health || exit 1"]
            interval: 30s
            timeout: 30s
            retries: 3
            start_period: 2m
        networks:
            - real-estate-network
    
    scheduler:
        image: apache/airflow:2.9.0-python3.9
        depends_on:
            webserver:
                condition: service_healthy
        volumes:
            - ./dags:/opt/airflow/dags
            - ./scripts/entrypoint.sh:/opt/airflow/scripts/entrypoint.sh
            - ./logs:/opt/airflow/logs
            - ./data:/opt/airflow/data:rw
            - ${GOOGLE_APPLICATION_CREDENTIALS_LOCAL}:/opt/airflow/secrets/key.json:ro
            - ./dbt_real_estate/profiles.yml:/usr/local/airflow/dbt/profiles.yml
        environment:
            - LOAD_EX=n
            - EXECUTOR=CeleryExecutor
            - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
            - AIRFLOW_UID=1000
            - AIRFLOW__LOGGING__BASE_LOG_FOLDER=/opt/airflow/logs
            - AIRFLOW__LOGGING__LOGGING_LEVEL=INFO
            - GOOGLE_APPLICATION_CREDENTIALS=/opt/airflow/secrets/key.json
        command: >
                bash -c "pip install -r requirements.txt &&
                        airflow db upgrade &&
                        airflow scheduler"
        networks:
            - real-estate-network

    postgres:
        image: postgres:14.0
        environment:
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
        logging:
            options:
                max-size: 10m
                max-file: "3"
        networks:
            - real-estate-network

networks:
    real-estate-network: